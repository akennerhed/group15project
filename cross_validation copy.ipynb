{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import export_text, DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>PSS_score</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>sleep_time</th>\n",
       "      <th>wake_time</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>PSQI_score</th>\n",
       "      <th>call_duration</th>\n",
       "      <th>num_calls</th>\n",
       "      <th>num_sms</th>\n",
       "      <th>screen_on_time</th>\n",
       "      <th>skin_conductance</th>\n",
       "      <th>accelerometer</th>\n",
       "      <th>mobility_radius</th>\n",
       "      <th>mobility_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2.322732</td>\n",
       "      <td>4.332193</td>\n",
       "      <td>1.185878</td>\n",
       "      <td>1.570213</td>\n",
       "      <td>3.782094</td>\n",
       "      <td>7.726792</td>\n",
       "      <td>5.190660</td>\n",
       "      <td>6.572069</td>\n",
       "      <td>1</td>\n",
       "      <td>3.924527</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>10.703714</td>\n",
       "      <td>3.115730</td>\n",
       "      <td>0.161717</td>\n",
       "      <td>1.145179</td>\n",
       "      <td>2.196851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1.761436</td>\n",
       "      <td>3.254120</td>\n",
       "      <td>3.907281</td>\n",
       "      <td>4.072512</td>\n",
       "      <td>1.997145</td>\n",
       "      <td>7.312674</td>\n",
       "      <td>6.170717</td>\n",
       "      <td>8.030168</td>\n",
       "      <td>4</td>\n",
       "      <td>58.318004</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>11.012939</td>\n",
       "      <td>0.959144</td>\n",
       "      <td>0.985587</td>\n",
       "      <td>1.021133</td>\n",
       "      <td>0.737825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>3.025887</td>\n",
       "      <td>1.855002</td>\n",
       "      <td>2.045900</td>\n",
       "      <td>2.317493</td>\n",
       "      <td>3.619225</td>\n",
       "      <td>6.992060</td>\n",
       "      <td>5.318825</td>\n",
       "      <td>7.102420</td>\n",
       "      <td>1</td>\n",
       "      <td>4.941043</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>4.877372</td>\n",
       "      <td>3.311629</td>\n",
       "      <td>1.877445</td>\n",
       "      <td>0.478179</td>\n",
       "      <td>0.911673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1.948370</td>\n",
       "      <td>4.966676</td>\n",
       "      <td>3.345225</td>\n",
       "      <td>1.607756</td>\n",
       "      <td>3.583524</td>\n",
       "      <td>8.886914</td>\n",
       "      <td>8.061075</td>\n",
       "      <td>8.123294</td>\n",
       "      <td>3</td>\n",
       "      <td>0.295373</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>3.462956</td>\n",
       "      <td>0.625721</td>\n",
       "      <td>0.494921</td>\n",
       "      <td>0.630549</td>\n",
       "      <td>3.911418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>3.343484</td>\n",
       "      <td>2.065936</td>\n",
       "      <td>3.137843</td>\n",
       "      <td>2.118061</td>\n",
       "      <td>2.567347</td>\n",
       "      <td>7.811705</td>\n",
       "      <td>7.312145</td>\n",
       "      <td>7.785143</td>\n",
       "      <td>3</td>\n",
       "      <td>22.300571</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.861046</td>\n",
       "      <td>0.622609</td>\n",
       "      <td>1.342600</td>\n",
       "      <td>0.254090</td>\n",
       "      <td>1.605132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>2.529821</td>\n",
       "      <td>2.339608</td>\n",
       "      <td>1.321208</td>\n",
       "      <td>4.204331</td>\n",
       "      <td>4.890738</td>\n",
       "      <td>8.823033</td>\n",
       "      <td>8.703758</td>\n",
       "      <td>8.661936</td>\n",
       "      <td>2</td>\n",
       "      <td>59.106125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.339248</td>\n",
       "      <td>4.045863</td>\n",
       "      <td>1.694037</td>\n",
       "      <td>0.859401</td>\n",
       "      <td>4.123621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>1.319100</td>\n",
       "      <td>4.500507</td>\n",
       "      <td>4.816983</td>\n",
       "      <td>2.416180</td>\n",
       "      <td>4.195933</td>\n",
       "      <td>5.260243</td>\n",
       "      <td>5.890244</td>\n",
       "      <td>6.456058</td>\n",
       "      <td>4</td>\n",
       "      <td>56.137068</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>10.694380</td>\n",
       "      <td>2.169768</td>\n",
       "      <td>1.657737</td>\n",
       "      <td>0.108480</td>\n",
       "      <td>2.242326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>1.899102</td>\n",
       "      <td>3.930147</td>\n",
       "      <td>4.047799</td>\n",
       "      <td>3.163160</td>\n",
       "      <td>2.559401</td>\n",
       "      <td>6.425568</td>\n",
       "      <td>7.978066</td>\n",
       "      <td>7.188921</td>\n",
       "      <td>3</td>\n",
       "      <td>58.102473</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>8.646478</td>\n",
       "      <td>4.995654</td>\n",
       "      <td>1.046666</td>\n",
       "      <td>0.508623</td>\n",
       "      <td>2.088313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>1.472408</td>\n",
       "      <td>1.712893</td>\n",
       "      <td>1.245082</td>\n",
       "      <td>4.187222</td>\n",
       "      <td>4.558563</td>\n",
       "      <td>5.453843</td>\n",
       "      <td>8.859173</td>\n",
       "      <td>7.355107</td>\n",
       "      <td>4</td>\n",
       "      <td>44.220070</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>4.086836</td>\n",
       "      <td>4.897873</td>\n",
       "      <td>1.605314</td>\n",
       "      <td>0.444716</td>\n",
       "      <td>4.741065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>3.152789</td>\n",
       "      <td>3.633976</td>\n",
       "      <td>2.387994</td>\n",
       "      <td>3.853524</td>\n",
       "      <td>1.147076</td>\n",
       "      <td>5.270021</td>\n",
       "      <td>6.658582</td>\n",
       "      <td>7.090551</td>\n",
       "      <td>4</td>\n",
       "      <td>36.342934</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>7.399881</td>\n",
       "      <td>3.279636</td>\n",
       "      <td>2.130984</td>\n",
       "      <td>1.347205</td>\n",
       "      <td>4.191338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                day  PSS_score  Openness  Conscientiousness  Extraversion  \\\n",
       "participant_id                                                              \n",
       "1                 1         34  2.322732           4.332193      1.185878   \n",
       "1                 2         37  1.761436           3.254120      3.907281   \n",
       "1                 3         30  3.025887           1.855002      2.045900   \n",
       "1                 4         16  1.948370           4.966676      3.345225   \n",
       "1                 5         32  3.343484           2.065936      3.137843   \n",
       "...             ...        ...       ...                ...           ...   \n",
       "100              26         30  2.529821           2.339608      1.321208   \n",
       "100              27         33  1.319100           4.500507      4.816983   \n",
       "100              28         30  1.899102           3.930147      4.047799   \n",
       "100              29         28  1.472408           1.712893      1.245082   \n",
       "100              30         10  3.152789           3.633976      2.387994   \n",
       "\n",
       "                Agreeableness  Neuroticism  sleep_time  wake_time  \\\n",
       "participant_id                                                      \n",
       "1                    1.570213     3.782094    7.726792   5.190660   \n",
       "1                    4.072512     1.997145    7.312674   6.170717   \n",
       "1                    2.317493     3.619225    6.992060   5.318825   \n",
       "1                    1.607756     3.583524    8.886914   8.061075   \n",
       "1                    2.118061     2.567347    7.811705   7.312145   \n",
       "...                       ...          ...         ...        ...   \n",
       "100                  4.204331     4.890738    8.823033   8.703758   \n",
       "100                  2.416180     4.195933    5.260243   5.890244   \n",
       "100                  3.163160     2.559401    6.425568   7.978066   \n",
       "100                  4.187222     4.558563    5.453843   8.859173   \n",
       "100                  3.853524     1.147076    5.270021   6.658582   \n",
       "\n",
       "                sleep_duration  PSQI_score  call_duration  num_calls  num_sms  \\\n",
       "participant_id                                                                  \n",
       "1                     6.572069           1       3.924527         12       32   \n",
       "1                     8.030168           4      58.318004          3       41   \n",
       "1                     7.102420           1       4.941043          4       48   \n",
       "1                     8.123294           3       0.295373         11       38   \n",
       "1                     7.785143           3      22.300571         17       17   \n",
       "...                        ...         ...            ...        ...      ...   \n",
       "100                   8.661936           2      59.106125          0        1   \n",
       "100                   6.456058           4      56.137068         12       17   \n",
       "100                   7.188921           3      58.102473         13       21   \n",
       "100                   7.355107           4      44.220070         17       10   \n",
       "100                   7.090551           4      36.342934         16       47   \n",
       "\n",
       "                screen_on_time  skin_conductance  accelerometer  \\\n",
       "participant_id                                                    \n",
       "1                    10.703714          3.115730       0.161717   \n",
       "1                    11.012939          0.959144       0.985587   \n",
       "1                     4.877372          3.311629       1.877445   \n",
       "1                     3.462956          0.625721       0.494921   \n",
       "1                     4.861046          0.622609       1.342600   \n",
       "...                        ...               ...            ...   \n",
       "100                  11.339248          4.045863       1.694037   \n",
       "100                  10.694380          2.169768       1.657737   \n",
       "100                   8.646478          4.995654       1.046666   \n",
       "100                   4.086836          4.897873       1.605314   \n",
       "100                   7.399881          3.279636       2.130984   \n",
       "\n",
       "                mobility_radius  mobility_distance  \n",
       "participant_id                                      \n",
       "1                      1.145179           2.196851  \n",
       "1                      1.021133           0.737825  \n",
       "1                      0.478179           0.911673  \n",
       "1                      0.630549           3.911418  \n",
       "1                      0.254090           1.605132  \n",
       "...                         ...                ...  \n",
       "100                    0.859401           4.123621  \n",
       "100                    0.108480           2.242326  \n",
       "100                    0.508623           2.088313  \n",
       "100                    0.444716           4.741065  \n",
       "100                    1.347205           4.191338  \n",
       "\n",
       "[3000 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"stress_detection.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primitive cross-validation. Separating randomly has the same effect.\n",
    "train_data = df.head(2500)\n",
    "val_data = df.tail(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Actual cross validation that we plan to use ###\n",
    "\n",
    "# # Get unique participant IDs\n",
    "# unique_ids = df.index.unique()\n",
    "\n",
    "# # Shuffle the IDs\n",
    "# np.random.seed(0) # Not truly random!\n",
    "# shuffled_ids = np.random.permutation(unique_ids)\n",
    "\n",
    "# # Split the IDs\n",
    "# n_train = int(len(shuffled_ids) * 0.8)\n",
    "# n_val = int(len(shuffled_ids) * 0.1)\n",
    "# n_test = len(shuffled_ids) - n_train - n_val\n",
    "\n",
    "# train_ids = shuffled_ids[:n_train]\n",
    "# val_ids = shuffled_ids[n_train:n_train + n_val]\n",
    "# test_ids = shuffled_ids[n_train + n_val:]\n",
    "\n",
    "# # Filter rows by IDs\n",
    "# train_data = df[df.index.isin(train_ids)]\n",
    "# val_data = df[df.index.isin(val_ids)]\n",
    "# test_data = df[df.index.isin(test_ids)]\n",
    "\n",
    "# # Print sizes\n",
    "# print(f\"Train size: {len(train_data)}\")\n",
    "# print(f\"Validation size: {len(val_data)}\")\n",
    "# print(f\"Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data.drop(columns=\"PSS_score\"), train_data.PSS_score\n",
    "X_val, y_val = val_data.drop(columns='PSS_score'), val_data['PSS_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>sleep_time</th>\n",
       "      <th>wake_time</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>PSQI_score</th>\n",
       "      <th>call_duration</th>\n",
       "      <th>num_calls</th>\n",
       "      <th>num_sms</th>\n",
       "      <th>screen_on_time</th>\n",
       "      <th>skin_conductance</th>\n",
       "      <th>accelerometer</th>\n",
       "      <th>mobility_radius</th>\n",
       "      <th>mobility_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322732</td>\n",
       "      <td>4.332193</td>\n",
       "      <td>1.185878</td>\n",
       "      <td>1.570213</td>\n",
       "      <td>3.782094</td>\n",
       "      <td>7.726792</td>\n",
       "      <td>5.190660</td>\n",
       "      <td>6.572069</td>\n",
       "      <td>1</td>\n",
       "      <td>3.924527</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>10.703714</td>\n",
       "      <td>3.115730</td>\n",
       "      <td>0.161717</td>\n",
       "      <td>1.145179</td>\n",
       "      <td>2.196851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.761436</td>\n",
       "      <td>3.254120</td>\n",
       "      <td>3.907281</td>\n",
       "      <td>4.072512</td>\n",
       "      <td>1.997145</td>\n",
       "      <td>7.312674</td>\n",
       "      <td>6.170717</td>\n",
       "      <td>8.030168</td>\n",
       "      <td>4</td>\n",
       "      <td>58.318004</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>11.012939</td>\n",
       "      <td>0.959144</td>\n",
       "      <td>0.985587</td>\n",
       "      <td>1.021133</td>\n",
       "      <td>0.737825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3.025887</td>\n",
       "      <td>1.855002</td>\n",
       "      <td>2.045900</td>\n",
       "      <td>2.317493</td>\n",
       "      <td>3.619225</td>\n",
       "      <td>6.992060</td>\n",
       "      <td>5.318825</td>\n",
       "      <td>7.102420</td>\n",
       "      <td>1</td>\n",
       "      <td>4.941043</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>4.877372</td>\n",
       "      <td>3.311629</td>\n",
       "      <td>1.877445</td>\n",
       "      <td>0.478179</td>\n",
       "      <td>0.911673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.948370</td>\n",
       "      <td>4.966676</td>\n",
       "      <td>3.345225</td>\n",
       "      <td>1.607756</td>\n",
       "      <td>3.583524</td>\n",
       "      <td>8.886914</td>\n",
       "      <td>8.061075</td>\n",
       "      <td>8.123294</td>\n",
       "      <td>3</td>\n",
       "      <td>0.295373</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>3.462956</td>\n",
       "      <td>0.625721</td>\n",
       "      <td>0.494921</td>\n",
       "      <td>0.630549</td>\n",
       "      <td>3.911418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3.343484</td>\n",
       "      <td>2.065936</td>\n",
       "      <td>3.137843</td>\n",
       "      <td>2.118061</td>\n",
       "      <td>2.567347</td>\n",
       "      <td>7.811705</td>\n",
       "      <td>7.312145</td>\n",
       "      <td>7.785143</td>\n",
       "      <td>3</td>\n",
       "      <td>22.300571</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.861046</td>\n",
       "      <td>0.622609</td>\n",
       "      <td>1.342600</td>\n",
       "      <td>0.254090</td>\n",
       "      <td>1.605132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>6</td>\n",
       "      <td>3.703781</td>\n",
       "      <td>1.296630</td>\n",
       "      <td>2.116691</td>\n",
       "      <td>2.039509</td>\n",
       "      <td>2.955296</td>\n",
       "      <td>5.676691</td>\n",
       "      <td>5.250972</td>\n",
       "      <td>8.780086</td>\n",
       "      <td>1</td>\n",
       "      <td>1.061940</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4.597160</td>\n",
       "      <td>1.445043</td>\n",
       "      <td>1.937237</td>\n",
       "      <td>0.579644</td>\n",
       "      <td>2.272117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>7</td>\n",
       "      <td>3.703037</td>\n",
       "      <td>4.259859</td>\n",
       "      <td>4.789652</td>\n",
       "      <td>2.067105</td>\n",
       "      <td>2.564628</td>\n",
       "      <td>5.240225</td>\n",
       "      <td>8.039434</td>\n",
       "      <td>7.551028</td>\n",
       "      <td>1</td>\n",
       "      <td>7.994803</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>1.489260</td>\n",
       "      <td>3.206102</td>\n",
       "      <td>2.292650</td>\n",
       "      <td>0.704083</td>\n",
       "      <td>2.648523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8</td>\n",
       "      <td>4.417820</td>\n",
       "      <td>2.882184</td>\n",
       "      <td>3.999049</td>\n",
       "      <td>1.526033</td>\n",
       "      <td>3.645911</td>\n",
       "      <td>7.686243</td>\n",
       "      <td>8.678028</td>\n",
       "      <td>6.185552</td>\n",
       "      <td>1</td>\n",
       "      <td>25.634404</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>7.541740</td>\n",
       "      <td>0.673305</td>\n",
       "      <td>1.537375</td>\n",
       "      <td>1.228914</td>\n",
       "      <td>4.174174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>9</td>\n",
       "      <td>4.093870</td>\n",
       "      <td>2.172721</td>\n",
       "      <td>3.680049</td>\n",
       "      <td>3.559307</td>\n",
       "      <td>1.037871</td>\n",
       "      <td>7.237319</td>\n",
       "      <td>8.596423</td>\n",
       "      <td>7.971472</td>\n",
       "      <td>1</td>\n",
       "      <td>50.302923</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>9.526293</td>\n",
       "      <td>0.501595</td>\n",
       "      <td>2.369035</td>\n",
       "      <td>0.216297</td>\n",
       "      <td>1.860958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>10</td>\n",
       "      <td>3.371741</td>\n",
       "      <td>2.009125</td>\n",
       "      <td>4.456898</td>\n",
       "      <td>4.591254</td>\n",
       "      <td>2.626220</td>\n",
       "      <td>6.327708</td>\n",
       "      <td>5.235494</td>\n",
       "      <td>7.736873</td>\n",
       "      <td>2</td>\n",
       "      <td>53.846313</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>7.617837</td>\n",
       "      <td>3.125967</td>\n",
       "      <td>0.931197</td>\n",
       "      <td>0.712262</td>\n",
       "      <td>4.464630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                day  Openness  Conscientiousness  Extraversion  Agreeableness  \\\n",
       "participant_id                                                                  \n",
       "1                 1  2.322732           4.332193      1.185878       1.570213   \n",
       "1                 2  1.761436           3.254120      3.907281       4.072512   \n",
       "1                 3  3.025887           1.855002      2.045900       2.317493   \n",
       "1                 4  1.948370           4.966676      3.345225       1.607756   \n",
       "1                 5  3.343484           2.065936      3.137843       2.118061   \n",
       "...             ...       ...                ...           ...            ...   \n",
       "84                6  3.703781           1.296630      2.116691       2.039509   \n",
       "84                7  3.703037           4.259859      4.789652       2.067105   \n",
       "84                8  4.417820           2.882184      3.999049       1.526033   \n",
       "84                9  4.093870           2.172721      3.680049       3.559307   \n",
       "84               10  3.371741           2.009125      4.456898       4.591254   \n",
       "\n",
       "                Neuroticism  sleep_time  wake_time  sleep_duration  \\\n",
       "participant_id                                                       \n",
       "1                  3.782094    7.726792   5.190660        6.572069   \n",
       "1                  1.997145    7.312674   6.170717        8.030168   \n",
       "1                  3.619225    6.992060   5.318825        7.102420   \n",
       "1                  3.583524    8.886914   8.061075        8.123294   \n",
       "1                  2.567347    7.811705   7.312145        7.785143   \n",
       "...                     ...         ...        ...             ...   \n",
       "84                 2.955296    5.676691   5.250972        8.780086   \n",
       "84                 2.564628    5.240225   8.039434        7.551028   \n",
       "84                 3.645911    7.686243   8.678028        6.185552   \n",
       "84                 1.037871    7.237319   8.596423        7.971472   \n",
       "84                 2.626220    6.327708   5.235494        7.736873   \n",
       "\n",
       "                PSQI_score  call_duration  num_calls  num_sms  screen_on_time  \\\n",
       "participant_id                                                                  \n",
       "1                        1       3.924527         12       32       10.703714   \n",
       "1                        4      58.318004          3       41       11.012939   \n",
       "1                        1       4.941043          4       48        4.877372   \n",
       "1                        3       0.295373         11       38        3.462956   \n",
       "1                        3      22.300571         17       17        4.861046   \n",
       "...                    ...            ...        ...      ...             ...   \n",
       "84                       1       1.061940          9        1        4.597160   \n",
       "84                       1       7.994803          9       19        1.489260   \n",
       "84                       1      25.634404         14       23        7.541740   \n",
       "84                       1      50.302923          8       32        9.526293   \n",
       "84                       2      53.846313         14        6        7.617837   \n",
       "\n",
       "                skin_conductance  accelerometer  mobility_radius  \\\n",
       "participant_id                                                     \n",
       "1                       3.115730       0.161717         1.145179   \n",
       "1                       0.959144       0.985587         1.021133   \n",
       "1                       3.311629       1.877445         0.478179   \n",
       "1                       0.625721       0.494921         0.630549   \n",
       "1                       0.622609       1.342600         0.254090   \n",
       "...                          ...            ...              ...   \n",
       "84                      1.445043       1.937237         0.579644   \n",
       "84                      3.206102       2.292650         0.704083   \n",
       "84                      0.673305       1.537375         1.228914   \n",
       "84                      0.501595       2.369035         0.216297   \n",
       "84                      3.125967       0.931197         0.712262   \n",
       "\n",
       "                mobility_distance  \n",
       "participant_id                     \n",
       "1                        2.196851  \n",
       "1                        0.737825  \n",
       "1                        0.911673  \n",
       "1                        3.911418  \n",
       "1                        1.605132  \n",
       "...                           ...  \n",
       "84                       2.272117  \n",
       "84                       2.648523  \n",
       "84                       4.174174  \n",
       "84                       1.860958  \n",
       "84                       4.464630  \n",
       "\n",
       "[2500 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = range(1, 21)  # Example: 1 to 20\n",
    "min_impurity_decrease_range = np.arange(0.0, 0.5, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 1, 'min_impurity_decrease': 0.35000000000000003}\n",
      "Best validation MSE: 71.496208\n"
     ]
    }
   ],
   "source": [
    "best_score = float('inf')  # Track the best score (lower MSE is better)\n",
    "best_params = None         # Track the best parameters\n",
    "results = []               # Store results for inspection\n",
    "\n",
    "# We will loop through each of our parameters to do grid search by hand\n",
    "for max_depth in max_depth_range:\n",
    "    for min_impurity_decrease in min_impurity_decrease_range:\n",
    "        # Create model\n",
    "        model = DecisionTreeRegressor(\n",
    "            criterion='squared_error',\n",
    "            max_depth=max_depth,\n",
    "            min_impurity_decrease=min_impurity_decrease\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "        ### Uncomment for best params on training data\n",
    "        # y_val_pred = model.predict(X_train)\n",
    "        # val_mse = mean_squared_error(y_train, y_val_pred)\n",
    "        \n",
    "        # Update results\n",
    "        results.append({\n",
    "            'max_depth': max_depth,\n",
    "            'min_impurity_decrease': min_impurity_decrease,\n",
    "            'val_mse': val_mse\n",
    "        })\n",
    "        if val_mse < best_score:\n",
    "            best_score = val_mse\n",
    "            best_params = {'max_depth': max_depth, 'min_impurity_decrease': min_impurity_decrease}\n",
    "\n",
    "# Output the best parameters and corresponding validation MSE\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation MSE: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeRegressor\u001b[49m(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_impurity_decrease\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.51\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model = DecisionTreeRegressor(criterion='squared_error', max_depth=2)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(criterion='squared_error', max_depth=1, min_impurity_decrease=0.51)\n",
    "# model = DecisionTreeRegressor(criterion='squared_error', max_depth=2)\n",
    "model.fit(X_train, y_train)\n",
    "fig = plt.figure()\n",
    "_ = tree.plot_tree(model,feature_names=X_train.columns)\n",
    "plt.title(\"Decision Tree\")\n",
    "# print(export_text(model, feature_names=X.columns))\n",
    "\n",
    "# Notes from prof:\n",
    "# Check MSE train and MSE test against each other\n",
    "# try min_impurity_decrease in regressor\n",
    "# only show first 3 layers on slides and interpret them, bigger font (make readable)\n",
    "# maybe decrease max_depth as last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.749136"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_model_train_hat = model.predict(X_train)\n",
    "mean_squared_error(y_train, y_model_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.749136"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_hat = [np.mean(y_train)] * len(y_train)\n",
    "mean_squared_error(y_pred=y_train_hat, y_true=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.31869600694445"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_hat = [np.mean(y_train)] * len(y_val)\n",
    "mean_squared_error(y_pred=y_val_hat, y_true=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.31869600694445"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(criterion='squared_error', max_depth=4, min_impurity_decrease=0.45)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_model_val_hat = model.predict(X_val)\n",
    "mean_squared_error(y_true=y_val, y_pred=y_model_val_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 20, 13, 37, 38, 27, 22, 22, 39, 22, 18, 36, 38, 15, 26, 14, 23,\n",
       "       25, 30, 12, 29, 26, 37, 20, 12, 17, 39, 26, 29, 35, 17, 31, 32, 30,\n",
       "       21, 37, 38, 28, 23, 33, 18, 14, 14, 11, 19, 27, 19, 12, 23, 14, 35,\n",
       "       13, 31, 39, 16, 31, 31, 16, 30, 37, 25, 37, 30, 36, 22, 26, 29, 23,\n",
       "       17, 24, 36, 15, 31, 20, 21, 16, 33, 27, 17, 33, 36, 22, 22, 27, 37,\n",
       "       39, 36, 21, 20, 24, 33, 33, 33, 29, 30, 12, 31, 34, 32, 19, 30, 19,\n",
       "       30, 33, 36, 15, 12, 18, 30, 17, 21, 16, 31, 11, 28, 11, 26, 23, 28,\n",
       "       24, 15, 29, 33, 30, 28, 16, 32, 18, 28, 35, 26, 15, 24, 21, 37, 18,\n",
       "       30, 35, 11, 12, 28, 11, 36, 37, 18, 23, 22, 16, 17, 15, 29, 13, 20,\n",
       "       36, 21, 35, 10, 29, 20, 35, 34, 38, 33, 15, 19, 19, 36, 28, 20, 13,\n",
       "       14, 14, 14, 18, 13, 35, 27, 23, 19, 17, 14, 39, 22, 35, 31, 20, 14,\n",
       "       29, 20, 13, 33, 12, 11, 13, 31, 21, 22, 29, 28, 11, 32, 13, 36, 13,\n",
       "       38, 33, 12, 24, 38, 17, 24, 30, 13, 30, 17, 12, 35, 21, 13, 12, 38,\n",
       "       31, 17, 12, 15, 32, 15, 10, 20, 12, 39, 25, 14, 11, 27, 26, 19, 38,\n",
       "       14, 19, 32, 17, 13, 22, 19, 23, 16, 38, 37, 28, 33, 20, 30, 21, 37,\n",
       "       14, 32, 18, 23, 22, 17, 26, 30, 27, 33, 17, 29, 39, 29, 32, 12, 10,\n",
       "       13, 18, 14, 35, 12, 39, 13, 32, 28, 15, 16, 21, 23, 17, 25, 38, 27,\n",
       "       27, 25, 20, 13, 12, 25, 11, 20, 37, 22, 30], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.PSS_score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.17232993152844"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.Lasso()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_model_val_hat = model.predict(X_val)\n",
    "mean_squared_error(y_true=y_val, y_pred=y_model_val_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming `df` is your DataFrame\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `df` is your DataFrame\n",
    "sns.pairplot(df, diag_kind='kde')  # `diag_kind='kde'` adds kernel density estimation to diagonal plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "_ = tree.plot_tree(model, feature_names=X_train.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
