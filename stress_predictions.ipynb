{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import export_text, DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>PSS_score</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>sleep_time</th>\n",
       "      <th>wake_time</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>PSQI_score</th>\n",
       "      <th>call_duration</th>\n",
       "      <th>num_calls</th>\n",
       "      <th>num_sms</th>\n",
       "      <th>screen_on_time</th>\n",
       "      <th>skin_conductance</th>\n",
       "      <th>accelerometer</th>\n",
       "      <th>mobility_radius</th>\n",
       "      <th>mobility_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2.322732</td>\n",
       "      <td>4.332193</td>\n",
       "      <td>1.185878</td>\n",
       "      <td>1.570213</td>\n",
       "      <td>3.782094</td>\n",
       "      <td>7.726792</td>\n",
       "      <td>5.190660</td>\n",
       "      <td>6.572069</td>\n",
       "      <td>1</td>\n",
       "      <td>3.924527</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>10.703714</td>\n",
       "      <td>3.115730</td>\n",
       "      <td>0.161717</td>\n",
       "      <td>1.145179</td>\n",
       "      <td>2.196851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1.761436</td>\n",
       "      <td>3.254120</td>\n",
       "      <td>3.907281</td>\n",
       "      <td>4.072512</td>\n",
       "      <td>1.997145</td>\n",
       "      <td>7.312674</td>\n",
       "      <td>6.170717</td>\n",
       "      <td>8.030168</td>\n",
       "      <td>4</td>\n",
       "      <td>58.318004</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>11.012939</td>\n",
       "      <td>0.959144</td>\n",
       "      <td>0.985587</td>\n",
       "      <td>1.021133</td>\n",
       "      <td>0.737825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>3.025887</td>\n",
       "      <td>1.855002</td>\n",
       "      <td>2.045900</td>\n",
       "      <td>2.317493</td>\n",
       "      <td>3.619225</td>\n",
       "      <td>6.992060</td>\n",
       "      <td>5.318825</td>\n",
       "      <td>7.102420</td>\n",
       "      <td>1</td>\n",
       "      <td>4.941043</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>4.877372</td>\n",
       "      <td>3.311629</td>\n",
       "      <td>1.877445</td>\n",
       "      <td>0.478179</td>\n",
       "      <td>0.911673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1.948370</td>\n",
       "      <td>4.966676</td>\n",
       "      <td>3.345225</td>\n",
       "      <td>1.607756</td>\n",
       "      <td>3.583524</td>\n",
       "      <td>8.886914</td>\n",
       "      <td>8.061075</td>\n",
       "      <td>8.123294</td>\n",
       "      <td>3</td>\n",
       "      <td>0.295373</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>3.462956</td>\n",
       "      <td>0.625721</td>\n",
       "      <td>0.494921</td>\n",
       "      <td>0.630549</td>\n",
       "      <td>3.911418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>3.343484</td>\n",
       "      <td>2.065936</td>\n",
       "      <td>3.137843</td>\n",
       "      <td>2.118061</td>\n",
       "      <td>2.567347</td>\n",
       "      <td>7.811705</td>\n",
       "      <td>7.312145</td>\n",
       "      <td>7.785143</td>\n",
       "      <td>3</td>\n",
       "      <td>22.300571</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.861046</td>\n",
       "      <td>0.622609</td>\n",
       "      <td>1.342600</td>\n",
       "      <td>0.254090</td>\n",
       "      <td>1.605132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>2.529821</td>\n",
       "      <td>2.339608</td>\n",
       "      <td>1.321208</td>\n",
       "      <td>4.204331</td>\n",
       "      <td>4.890738</td>\n",
       "      <td>8.823033</td>\n",
       "      <td>8.703758</td>\n",
       "      <td>8.661936</td>\n",
       "      <td>2</td>\n",
       "      <td>59.106125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.339248</td>\n",
       "      <td>4.045863</td>\n",
       "      <td>1.694037</td>\n",
       "      <td>0.859401</td>\n",
       "      <td>4.123621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>1.319100</td>\n",
       "      <td>4.500507</td>\n",
       "      <td>4.816983</td>\n",
       "      <td>2.416180</td>\n",
       "      <td>4.195933</td>\n",
       "      <td>5.260243</td>\n",
       "      <td>5.890244</td>\n",
       "      <td>6.456058</td>\n",
       "      <td>4</td>\n",
       "      <td>56.137068</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>10.694380</td>\n",
       "      <td>2.169768</td>\n",
       "      <td>1.657737</td>\n",
       "      <td>0.108480</td>\n",
       "      <td>2.242326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>1.899102</td>\n",
       "      <td>3.930147</td>\n",
       "      <td>4.047799</td>\n",
       "      <td>3.163160</td>\n",
       "      <td>2.559401</td>\n",
       "      <td>6.425568</td>\n",
       "      <td>7.978066</td>\n",
       "      <td>7.188921</td>\n",
       "      <td>3</td>\n",
       "      <td>58.102473</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>8.646478</td>\n",
       "      <td>4.995654</td>\n",
       "      <td>1.046666</td>\n",
       "      <td>0.508623</td>\n",
       "      <td>2.088313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>1.472408</td>\n",
       "      <td>1.712893</td>\n",
       "      <td>1.245082</td>\n",
       "      <td>4.187222</td>\n",
       "      <td>4.558563</td>\n",
       "      <td>5.453843</td>\n",
       "      <td>8.859173</td>\n",
       "      <td>7.355107</td>\n",
       "      <td>4</td>\n",
       "      <td>44.220070</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>4.086836</td>\n",
       "      <td>4.897873</td>\n",
       "      <td>1.605314</td>\n",
       "      <td>0.444716</td>\n",
       "      <td>4.741065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>3.152789</td>\n",
       "      <td>3.633976</td>\n",
       "      <td>2.387994</td>\n",
       "      <td>3.853524</td>\n",
       "      <td>1.147076</td>\n",
       "      <td>5.270021</td>\n",
       "      <td>6.658582</td>\n",
       "      <td>7.090551</td>\n",
       "      <td>4</td>\n",
       "      <td>36.342934</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>7.399881</td>\n",
       "      <td>3.279636</td>\n",
       "      <td>2.130984</td>\n",
       "      <td>1.347205</td>\n",
       "      <td>4.191338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                day  PSS_score  Openness  Conscientiousness  Extraversion  \\\n",
       "participant_id                                                              \n",
       "1                 1         34  2.322732           4.332193      1.185878   \n",
       "1                 2         37  1.761436           3.254120      3.907281   \n",
       "1                 3         30  3.025887           1.855002      2.045900   \n",
       "1                 4         16  1.948370           4.966676      3.345225   \n",
       "1                 5         32  3.343484           2.065936      3.137843   \n",
       "...             ...        ...       ...                ...           ...   \n",
       "100              26         30  2.529821           2.339608      1.321208   \n",
       "100              27         33  1.319100           4.500507      4.816983   \n",
       "100              28         30  1.899102           3.930147      4.047799   \n",
       "100              29         28  1.472408           1.712893      1.245082   \n",
       "100              30         10  3.152789           3.633976      2.387994   \n",
       "\n",
       "                Agreeableness  Neuroticism  sleep_time  wake_time  \\\n",
       "participant_id                                                      \n",
       "1                    1.570213     3.782094    7.726792   5.190660   \n",
       "1                    4.072512     1.997145    7.312674   6.170717   \n",
       "1                    2.317493     3.619225    6.992060   5.318825   \n",
       "1                    1.607756     3.583524    8.886914   8.061075   \n",
       "1                    2.118061     2.567347    7.811705   7.312145   \n",
       "...                       ...          ...         ...        ...   \n",
       "100                  4.204331     4.890738    8.823033   8.703758   \n",
       "100                  2.416180     4.195933    5.260243   5.890244   \n",
       "100                  3.163160     2.559401    6.425568   7.978066   \n",
       "100                  4.187222     4.558563    5.453843   8.859173   \n",
       "100                  3.853524     1.147076    5.270021   6.658582   \n",
       "\n",
       "                sleep_duration  PSQI_score  call_duration  num_calls  num_sms  \\\n",
       "participant_id                                                                  \n",
       "1                     6.572069           1       3.924527         12       32   \n",
       "1                     8.030168           4      58.318004          3       41   \n",
       "1                     7.102420           1       4.941043          4       48   \n",
       "1                     8.123294           3       0.295373         11       38   \n",
       "1                     7.785143           3      22.300571         17       17   \n",
       "...                        ...         ...            ...        ...      ...   \n",
       "100                   8.661936           2      59.106125          0        1   \n",
       "100                   6.456058           4      56.137068         12       17   \n",
       "100                   7.188921           3      58.102473         13       21   \n",
       "100                   7.355107           4      44.220070         17       10   \n",
       "100                   7.090551           4      36.342934         16       47   \n",
       "\n",
       "                screen_on_time  skin_conductance  accelerometer  \\\n",
       "participant_id                                                    \n",
       "1                    10.703714          3.115730       0.161717   \n",
       "1                    11.012939          0.959144       0.985587   \n",
       "1                     4.877372          3.311629       1.877445   \n",
       "1                     3.462956          0.625721       0.494921   \n",
       "1                     4.861046          0.622609       1.342600   \n",
       "...                        ...               ...            ...   \n",
       "100                  11.339248          4.045863       1.694037   \n",
       "100                  10.694380          2.169768       1.657737   \n",
       "100                   8.646478          4.995654       1.046666   \n",
       "100                   4.086836          4.897873       1.605314   \n",
       "100                   7.399881          3.279636       2.130984   \n",
       "\n",
       "                mobility_radius  mobility_distance  \n",
       "participant_id                                      \n",
       "1                      1.145179           2.196851  \n",
       "1                      1.021133           0.737825  \n",
       "1                      0.478179           0.911673  \n",
       "1                      0.630549           3.911418  \n",
       "1                      0.254090           1.605132  \n",
       "...                         ...                ...  \n",
       "100                    0.859401           4.123621  \n",
       "100                    0.108480           2.242326  \n",
       "100                    0.508623           2.088313  \n",
       "100                    0.444716           4.741065  \n",
       "100                    1.347205           4.191338  \n",
       "\n",
       "[3000 rows x 19 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"stress_detection.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2400\n",
      "Validation size: 300\n",
      "Test size: 300\n"
     ]
    }
   ],
   "source": [
    "## Actual cross validation that we plan to use ###\n",
    "\n",
    "# Get unique participant IDs\n",
    "unique_ids = df.index.unique()\n",
    "\n",
    "# Shuffle the IDs\n",
    "np.random.seed(11) # Not truly random!\n",
    "shuffled_ids = np.random.permutation(unique_ids)\n",
    "\n",
    "# Split the IDs\n",
    "n_train = int(len(shuffled_ids) * 0.8)\n",
    "n_val = int(len(shuffled_ids) * 0.1)\n",
    "n_test = len(shuffled_ids) - n_train - n_val\n",
    "\n",
    "train_ids = shuffled_ids[:n_train]\n",
    "val_ids = shuffled_ids[n_train:n_train + n_val]\n",
    "test_ids = shuffled_ids[n_train + n_val:]\n",
    "\n",
    "# Filter rows by IDs\n",
    "train_data = df[df.index.isin(train_ids)]\n",
    "val_data = df[df.index.isin(val_ids)]\n",
    "test_data = df[df.index.isin(test_ids)]\n",
    "\n",
    "# Print sizes\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Validation size: {len(val_data)}\")\n",
    "print(f\"Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data.drop(columns=\"PSS_score\"), train_data.PSS_score\n",
    "X_val, y_val = val_data.drop(columns='PSS_score'), val_data.PSS_score\n",
    "X_test, y_test = test_data.drop(columns='PSS_score'), test_data.PSS_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 3, 'min_impurity_decrease': 0.25}\n",
      "Best validation MSE: 80.15485548590637\n"
     ]
    }
   ],
   "source": [
    "best_score = float('inf')\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "max_depth_range = range(1, 21)  # Example: 1 to 20\n",
    "min_impurity_decrease_range = np.arange(0.0, 0.5, 0.05)\n",
    "\n",
    "# Loop through each of our parameters to do grid search by hand\n",
    "for max_depth in max_depth_range:\n",
    "    for min_impurity_decrease in min_impurity_decrease_range:\n",
    "        # Create model\n",
    "        model = DecisionTreeRegressor(\n",
    "            criterion='squared_error',\n",
    "            max_depth=max_depth,\n",
    "            min_impurity_decrease=min_impurity_decrease\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "        \n",
    "        # Update results\n",
    "        results.append({\n",
    "            'max_depth': max_depth,\n",
    "            'min_impurity_decrease': min_impurity_decrease,\n",
    "            'val_mse': val_mse\n",
    "        })\n",
    "        if val_mse < best_score:\n",
    "            best_score = val_mse\n",
    "            best_params = {'max_depth': max_depth, 'min_impurity_decrease': min_impurity_decrease}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation MSE: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.90826822916667\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(criterion='squared_error', max_depth=1, min_impurity_decrease=0.45)\n",
    "# model = DecisionTreeRegressor(criterion='squared_error', max_depth=2)\n",
    "model.fit(X_train, y_train)\n",
    "fig = plt.figure(figsize=(4, 2))\n",
    "_ = tree.plot_tree(model,feature_names=X_train.columns)\n",
    "plt.title(\"Decision Tree\")\n",
    "y_model_test_hat = model.predict(X_test)\n",
    "print(mean_squared_error(y_true=y_test, y_pred=y_model_test_hat))\n",
    "# print(export_text(model, feature_names=X.columns))\n",
    "\n",
    "# Notes from prof:\n",
    "# Check MSE train and MSE test against each other\n",
    "# try min_impurity_decrease in regressor\n",
    "# only show first 3 layers on slides and interpret them, bigger font (make readable)\n",
    "# maybe decrease max_depth as last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MSE of our model on test data ###\n",
    "# y_val_hat = model.predict()\n",
    "# mean_squared_error(y_val, y_val_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.90826822916667"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_hat = [np.mean(y_train)] * len(y_val)\n",
    "mean_squared_error(y_test, y_val_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.72541747994592"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Creating a tree with max_depth=4 performs worse than a model that guesses the mean ###\n",
    "model = DecisionTreeRegressor(criterion='squared_error', max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_model_val_hat = model.predict(X_val)\n",
    "mean_squared_error(y_true=y_val, y_pred=y_model_val_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.59774406324048"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### A linear model still does worse than guessing the mean each time ###\n",
    "from sklearn.linear_model import LinearRegression\n",
    "used_variables = [\"Openness\", \"Neuroticism\", \"mobility_distance\"]\n",
    "X_train2 = X_train[used_variables]\n",
    "X_val2 = X_val[used_variables]\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train2, y_train)\n",
    "y_hat2_linear = linear_model.predict(X_val2)\n",
    "mean_squared_error(y_true=y_val, y_pred=y_hat2_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.9354687994868"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# y_model_val_hat = model.predict(X_val)\n",
    "# mean_squared_error(y_true=y_val, y_pred=y_model_val_hat)\n",
    "y_model_val_hat = model.predict(X_test)\n",
    "mean_squared_error(y_true=y_test, y_pred=y_model_val_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.2}\n",
      "Best validation MSE: 80.1187036454096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianfr\\anaconda3\\envs\\geocat\\Lib\\site-packages\\sklearn\\base.py:1474: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\ianfr\\anaconda3\\envs\\geocat\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ianfr\\anaconda3\\envs\\geocat\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.759e+04, tolerance: 1.763e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "best_score = float('inf')\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "alphas = np.arange(0, 10, 0.1)  # Example: 1 to 20\n",
    "\n",
    "# Loop through each of our parameters to do grid search by hand\n",
    "for alpha in alphas:\n",
    "    # Create model\n",
    "    model = Lasso(\n",
    "        alpha=alpha\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "    \n",
    "    # Update results\n",
    "    results.append({\n",
    "        'alpha': alpha,\n",
    "        'val_mse': val_mse\n",
    "    })\n",
    "    if val_mse < best_score:\n",
    "        best_score = val_mse\n",
    "        best_params = {'alpha': alpha}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation MSE: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.1187036454096"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(alpha=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_model_val_hat = model.predict(X_val)\n",
    "mean_squared_error(y_true=y_val, y_pred=y_model_val_hat)\n",
    "\n",
    "# y_model_test_hat = model.predict(X_test)\n",
    "# mean_squared_error(y_true=y_test, y_pred=y_model_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.01037263,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>PSS_score</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>sleep_time</th>\n",
       "      <th>wake_time</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>PSQI_score</th>\n",
       "      <th>call_duration</th>\n",
       "      <th>num_calls</th>\n",
       "      <th>num_sms</th>\n",
       "      <th>screen_on_time</th>\n",
       "      <th>skin_conductance</th>\n",
       "      <th>accelerometer</th>\n",
       "      <th>mobility_radius</th>\n",
       "      <th>mobility_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2.322732</td>\n",
       "      <td>4.332193</td>\n",
       "      <td>1.185878</td>\n",
       "      <td>1.570213</td>\n",
       "      <td>3.782094</td>\n",
       "      <td>7.726792</td>\n",
       "      <td>5.190660</td>\n",
       "      <td>6.572069</td>\n",
       "      <td>1</td>\n",
       "      <td>3.924527</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>10.703714</td>\n",
       "      <td>3.115730</td>\n",
       "      <td>0.161717</td>\n",
       "      <td>1.145179</td>\n",
       "      <td>2.196851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1.761436</td>\n",
       "      <td>3.254120</td>\n",
       "      <td>3.907281</td>\n",
       "      <td>4.072512</td>\n",
       "      <td>1.997145</td>\n",
       "      <td>7.312674</td>\n",
       "      <td>6.170717</td>\n",
       "      <td>8.030168</td>\n",
       "      <td>4</td>\n",
       "      <td>58.318004</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>11.012939</td>\n",
       "      <td>0.959144</td>\n",
       "      <td>0.985587</td>\n",
       "      <td>1.021133</td>\n",
       "      <td>0.737825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>3.025887</td>\n",
       "      <td>1.855002</td>\n",
       "      <td>2.045900</td>\n",
       "      <td>2.317493</td>\n",
       "      <td>3.619225</td>\n",
       "      <td>6.992060</td>\n",
       "      <td>5.318825</td>\n",
       "      <td>7.102420</td>\n",
       "      <td>1</td>\n",
       "      <td>4.941043</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>4.877372</td>\n",
       "      <td>3.311629</td>\n",
       "      <td>1.877445</td>\n",
       "      <td>0.478179</td>\n",
       "      <td>0.911673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1.948370</td>\n",
       "      <td>4.966676</td>\n",
       "      <td>3.345225</td>\n",
       "      <td>1.607756</td>\n",
       "      <td>3.583524</td>\n",
       "      <td>8.886914</td>\n",
       "      <td>8.061075</td>\n",
       "      <td>8.123294</td>\n",
       "      <td>3</td>\n",
       "      <td>0.295373</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>3.462956</td>\n",
       "      <td>0.625721</td>\n",
       "      <td>0.494921</td>\n",
       "      <td>0.630549</td>\n",
       "      <td>3.911418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>3.343484</td>\n",
       "      <td>2.065936</td>\n",
       "      <td>3.137843</td>\n",
       "      <td>2.118061</td>\n",
       "      <td>2.567347</td>\n",
       "      <td>7.811705</td>\n",
       "      <td>7.312145</td>\n",
       "      <td>7.785143</td>\n",
       "      <td>3</td>\n",
       "      <td>22.300571</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.861046</td>\n",
       "      <td>0.622609</td>\n",
       "      <td>1.342600</td>\n",
       "      <td>0.254090</td>\n",
       "      <td>1.605132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>2.529821</td>\n",
       "      <td>2.339608</td>\n",
       "      <td>1.321208</td>\n",
       "      <td>4.204331</td>\n",
       "      <td>4.890738</td>\n",
       "      <td>8.823033</td>\n",
       "      <td>8.703758</td>\n",
       "      <td>8.661936</td>\n",
       "      <td>2</td>\n",
       "      <td>59.106125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.339248</td>\n",
       "      <td>4.045863</td>\n",
       "      <td>1.694037</td>\n",
       "      <td>0.859401</td>\n",
       "      <td>4.123621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>1.319100</td>\n",
       "      <td>4.500507</td>\n",
       "      <td>4.816983</td>\n",
       "      <td>2.416180</td>\n",
       "      <td>4.195933</td>\n",
       "      <td>5.260243</td>\n",
       "      <td>5.890244</td>\n",
       "      <td>6.456058</td>\n",
       "      <td>4</td>\n",
       "      <td>56.137068</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>10.694380</td>\n",
       "      <td>2.169768</td>\n",
       "      <td>1.657737</td>\n",
       "      <td>0.108480</td>\n",
       "      <td>2.242326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>1.899102</td>\n",
       "      <td>3.930147</td>\n",
       "      <td>4.047799</td>\n",
       "      <td>3.163160</td>\n",
       "      <td>2.559401</td>\n",
       "      <td>6.425568</td>\n",
       "      <td>7.978066</td>\n",
       "      <td>7.188921</td>\n",
       "      <td>3</td>\n",
       "      <td>58.102473</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>8.646478</td>\n",
       "      <td>4.995654</td>\n",
       "      <td>1.046666</td>\n",
       "      <td>0.508623</td>\n",
       "      <td>2.088313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>1.472408</td>\n",
       "      <td>1.712893</td>\n",
       "      <td>1.245082</td>\n",
       "      <td>4.187222</td>\n",
       "      <td>4.558563</td>\n",
       "      <td>5.453843</td>\n",
       "      <td>8.859173</td>\n",
       "      <td>7.355107</td>\n",
       "      <td>4</td>\n",
       "      <td>44.220070</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>4.086836</td>\n",
       "      <td>4.897873</td>\n",
       "      <td>1.605314</td>\n",
       "      <td>0.444716</td>\n",
       "      <td>4.741065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>3.152789</td>\n",
       "      <td>3.633976</td>\n",
       "      <td>2.387994</td>\n",
       "      <td>3.853524</td>\n",
       "      <td>1.147076</td>\n",
       "      <td>5.270021</td>\n",
       "      <td>6.658582</td>\n",
       "      <td>7.090551</td>\n",
       "      <td>4</td>\n",
       "      <td>36.342934</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>7.399881</td>\n",
       "      <td>3.279636</td>\n",
       "      <td>2.130984</td>\n",
       "      <td>1.347205</td>\n",
       "      <td>4.191338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                day  PSS_score  Openness  Conscientiousness  Extraversion  \\\n",
       "participant_id                                                              \n",
       "1                 1         34  2.322732           4.332193      1.185878   \n",
       "1                 2         37  1.761436           3.254120      3.907281   \n",
       "1                 3         30  3.025887           1.855002      2.045900   \n",
       "1                 4         16  1.948370           4.966676      3.345225   \n",
       "1                 5         32  3.343484           2.065936      3.137843   \n",
       "...             ...        ...       ...                ...           ...   \n",
       "100              26         30  2.529821           2.339608      1.321208   \n",
       "100              27         33  1.319100           4.500507      4.816983   \n",
       "100              28         30  1.899102           3.930147      4.047799   \n",
       "100              29         28  1.472408           1.712893      1.245082   \n",
       "100              30         10  3.152789           3.633976      2.387994   \n",
       "\n",
       "                Agreeableness  Neuroticism  sleep_time  wake_time  \\\n",
       "participant_id                                                      \n",
       "1                    1.570213     3.782094    7.726792   5.190660   \n",
       "1                    4.072512     1.997145    7.312674   6.170717   \n",
       "1                    2.317493     3.619225    6.992060   5.318825   \n",
       "1                    1.607756     3.583524    8.886914   8.061075   \n",
       "1                    2.118061     2.567347    7.811705   7.312145   \n",
       "...                       ...          ...         ...        ...   \n",
       "100                  4.204331     4.890738    8.823033   8.703758   \n",
       "100                  2.416180     4.195933    5.260243   5.890244   \n",
       "100                  3.163160     2.559401    6.425568   7.978066   \n",
       "100                  4.187222     4.558563    5.453843   8.859173   \n",
       "100                  3.853524     1.147076    5.270021   6.658582   \n",
       "\n",
       "                sleep_duration  PSQI_score  call_duration  num_calls  num_sms  \\\n",
       "participant_id                                                                  \n",
       "1                     6.572069           1       3.924527         12       32   \n",
       "1                     8.030168           4      58.318004          3       41   \n",
       "1                     7.102420           1       4.941043          4       48   \n",
       "1                     8.123294           3       0.295373         11       38   \n",
       "1                     7.785143           3      22.300571         17       17   \n",
       "...                        ...         ...            ...        ...      ...   \n",
       "100                   8.661936           2      59.106125          0        1   \n",
       "100                   6.456058           4      56.137068         12       17   \n",
       "100                   7.188921           3      58.102473         13       21   \n",
       "100                   7.355107           4      44.220070         17       10   \n",
       "100                   7.090551           4      36.342934         16       47   \n",
       "\n",
       "                screen_on_time  skin_conductance  accelerometer  \\\n",
       "participant_id                                                    \n",
       "1                    10.703714          3.115730       0.161717   \n",
       "1                    11.012939          0.959144       0.985587   \n",
       "1                     4.877372          3.311629       1.877445   \n",
       "1                     3.462956          0.625721       0.494921   \n",
       "1                     4.861046          0.622609       1.342600   \n",
       "...                        ...               ...            ...   \n",
       "100                  11.339248          4.045863       1.694037   \n",
       "100                  10.694380          2.169768       1.657737   \n",
       "100                   8.646478          4.995654       1.046666   \n",
       "100                   4.086836          4.897873       1.605314   \n",
       "100                   7.399881          3.279636       2.130984   \n",
       "\n",
       "                mobility_radius  mobility_distance  \n",
       "participant_id                                      \n",
       "1                      1.145179           2.196851  \n",
       "1                      1.021133           0.737825  \n",
       "1                      0.478179           0.911673  \n",
       "1                      0.630549           3.911418  \n",
       "1                      0.254090           1.605132  \n",
       "...                         ...                ...  \n",
       "100                    0.859401           4.123621  \n",
       "100                    0.108480           2.242326  \n",
       "100                    0.508623           2.088313  \n",
       "100                    0.444716           4.741065  \n",
       "100                    1.347205           4.191338  \n",
       "\n",
       "[3000 rows x 19 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
